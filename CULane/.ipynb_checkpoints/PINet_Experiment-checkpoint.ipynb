{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd43244-d400-45e7-a71e-3b632710c435",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61bee737-88a3-4908-8372-ab9ac6aaecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "##\n",
    "##  Data loader source code for TuSimple dataset\n",
    "##\n",
    "#########################################################################\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from configs.parameters import DATASET_CFG\n",
    "\n",
    "#########################################################################\n",
    "## some iamge transform utils\n",
    "#########################################################################\n",
    "def Translate_Points(point,translation): \n",
    "    point = point + translation \n",
    "    \n",
    "    return point\n",
    "\n",
    "def Rotate_Points(origin, point, angle):\n",
    "    ox, oy = origin\n",
    "    px, py = point\n",
    "\n",
    "    qx = ox + math.cos(angle) * (px - ox) - math.sin(angle) * (py - oy)\n",
    "    qy = oy + math.sin(angle) * (px - ox) + math.cos(angle) * (py - oy)\n",
    "    return qx, qy\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "## Data loader class\n",
    "#########################################################################\n",
    "class DataGenerator(object):\n",
    "    ################################################################################\n",
    "    ## initialize (load data set from url)\n",
    "    ################################################################################\n",
    "    def __init__(self):\n",
    "        # self.p = Parameters()\n",
    "        self.dataset_cfg = DATASET_CFG\n",
    "        self.dataset_root = Path(self.dataset_cfg['dataset_root_dir'])\n",
    "\n",
    "        # Train & Test Set\n",
    "        self.train_set = os.path.join(self.dataset_root, f\"list/train.txt\")\n",
    "        # print(f\"Training Set >> {self.train_set}\")\n",
    "        self.test_set = os.path.join(self.dataset_cfg[\"dataset_root_dir\"], f\"list/test.txt\")\n",
    "\n",
    "        # load training set\n",
    "        self.train_data = []\n",
    "        \n",
    "        with open(self.train_set) as f:\n",
    "            self.train_data = f.readlines()\n",
    "\n",
    "        self.size_train = len(self.train_data)\n",
    "        # print(f\"[Debug] Train data >> {self.train_data}\")\n",
    "\n",
    "        # load test set\n",
    "        self.test_data = []\n",
    "        with open(self.test_set) as f:\n",
    "            self.test_data = f.readlines()\n",
    "\n",
    "        self.size_test = len(self.test_data)\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Generate data as much as batchsize and augment data (filp, translation, rotation, gaussian noise, scaling)\n",
    "    #################################################################################################################\n",
    "    def Generate(self, sampling_list = None): \n",
    "        cuts = [(b, min(b + self.dataset_cfg[\"batch_size\"], self.size_train)) for b in range(0, self.size_train, self.dataset_cfg[\"batch_size\"])]\n",
    "        random.shuffle(self.train_data)\n",
    "        random.shuffle(self.train_data)\n",
    "        random.shuffle(self.train_data)\n",
    "        for start, end in cuts:\n",
    "            # resize original image to 512*256\n",
    "            self.inputs, self.target_lanes, self.target_h, self.test_image, self.data_list = self.Resize_data(start, end, sampling_list)\n",
    "            \n",
    "            self.actual_batchsize = self.inputs.shape[0]\n",
    "            self.Flip()\n",
    "            self.Translation()\n",
    "            self.Rotate()\n",
    "            self.Gaussian()\n",
    "            self.Change_intensity()\n",
    "            self.Shadow()\n",
    "\n",
    "            yield self.inputs/255.0, self.target_lanes, self.target_h, self.test_image/255.0, self.data_list  # generate normalized image\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Generate test data\n",
    "    #################################################################################################################\n",
    "    def Generate_Test(self): \n",
    "        cuts = [(b, min(b + self.dataset_cfg[\"batch_size\"], self.size_test)) for b in range(0, self.size_test, self.dataset_cfg[\"batch_size\"])]\n",
    "        for start, end in cuts:\n",
    "            test_image, path, ratio_w, ratio_h, target_h, target_lanes = self.Resize_data_test(start, end)\n",
    "            yield test_image/255.0, ratio_w, ratio_h, path, target_h, target_lanes\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## resize original image to 512*256 and matching correspond points\n",
    "    #################################################################################################################\n",
    "\n",
    "    def Resize_data_test(self, start, end):\n",
    "        inputs = []\n",
    "        path = []\n",
    "        target_lanes = []\n",
    "        target_h = []\n",
    "\n",
    "        for i in range(start, end):\n",
    "            test_img = self.test_data[i]\n",
    "            # print(f\"[Debug] Data:: {data}\")\n",
    "            # image_path = os.path.join(self.dataset_root, Path(data))\n",
    "            image_path = os.path.join(self.dataset_root, test_img[0:-1])\n",
    "            # img_pth = self.p.test_root_url+data[1:-1]\n",
    "            # print(os.path.exists(img_pth))\n",
    "            # temp_image_d = cv2.imread(self.p.test_root_url+data[0:-1])\n",
    "            # print(temp_image_d.shape)\n",
    "            temp_image = cv2.imread(image_path)\n",
    "            original_size_x = temp_image.shape[1]\n",
    "            original_size_y = temp_image.shape[0]\n",
    "            ratio_w = self.dataset_cfg['img_width']*1.0/temp_image.shape[1]\n",
    "            ratio_h = self.dataset_cfg['img_height']*1.0/temp_image.shape[0]\n",
    "            temp_image = cv2.resize(temp_image, (self.dataset_cfg['img_width'], self.dataset_cfg['img_height']))\n",
    "            inputs.append( np.rollaxis(temp_image, axis=2, start=0) )\n",
    "            path.append(test_img[0:-1])\n",
    "\n",
    "            temp_lanes = []\n",
    "            temp_h = []\n",
    "\n",
    "            # annoatation = self.p.test_root_url+test_img[0:-4]+\"lines.txt\"\n",
    "            annoatation = os.path.join(self.dataset_root, f\"{test_img[0:-4]}lines.txt\")\n",
    "            # print(f\"[debug]: Annotation >> {annoatation}\")\n",
    "\n",
    "            # print(f\"[Debug]: annotation >>> {annoatation}\")\n",
    "            with open(annoatation) as f:\n",
    "                annoatation_data = f.readlines()\n",
    "            # print(f\"[Debug]: test annotation data_j >>> {annoatation_data}\")\n",
    "            for j in annoatation_data:\n",
    "                # print(f\"[Debug]: J ann > {j}\")\n",
    "                \n",
    "                x = []\n",
    "                y = []\n",
    "                temp_x = j.split()[0::2]\n",
    "                # print(f\"[Debug]: temp_x > {temp_x}\")\n",
    "                temp_y = j.split()[1::2]\n",
    "                # print(f\"[Debug]: temp_y > {temp_y}\")\n",
    "                # print(f\"Temp_X >>> {temp_x}\")\n",
    "                # print(f\"Temp_Y >>> \", temp_y)\n",
    "\n",
    "                for k in range(len(temp_x)):\n",
    "                    x_value = float(temp_x[k])\n",
    "                    y_value = int(float(temp_y[k]))\n",
    "                    if 0 < x_value < original_size_x and 0 < y_value < original_size_y:\n",
    "                        x.append( x_value )\n",
    "                        y.append( y_value )\n",
    "\n",
    "                temp_lanes.append( x )\n",
    "                temp_h.append( y )\n",
    "            target_lanes.append(np.array(temp_lanes))\n",
    "            target_h.append(np.array(temp_h))\n",
    "\n",
    "        return np.array(inputs), path, ratio_w, ratio_h, target_h, target_lanes\n",
    "\n",
    "    def Resize_data(self, start, end, sampling_list):\n",
    "        inputs = []\n",
    "        target_lanes = []\n",
    "        target_h = []\n",
    "        data_list = []\n",
    "\n",
    "        # choose data from each number of lanes\n",
    "        for i in range(start, end):\n",
    "\n",
    "            if sampling_list == None:\n",
    "                train_img = random.sample(self.train_data, 1)[0]\n",
    "                #data = self.train_data[0]\n",
    "                data_list.append(train_img)\n",
    "            elif len(sampling_list) < 10:\n",
    "                train_img = random.sample(self.train_data, 1)[0]\n",
    "                data_list.append(train_img)\n",
    "            else:            \n",
    "                choose = random.random()\n",
    "                if choose > 0.2:\n",
    "                    train_img = random.sample(self.train_data, 1)[0]\n",
    "                    data_list.append(train_img)\n",
    "                else:\n",
    "                    train_img = random.sample(sampling_list, 1)[0]\n",
    "                    data_list.append(train_img)\n",
    "\n",
    "            # train set image\n",
    "            print(f\"Data >>> {train_img[0:-1]}\")\n",
    "            \n",
    "            temp_image = cv2.imread(os.path.join(self.dataset_root, train_img[0:-1]))\n",
    "            if i==start:\n",
    "                print(train_img[1:-1])\n",
    "            original_size_x = temp_image.shape[1]\n",
    "            original_size_y = temp_image.shape[0]\n",
    "            ratio_w = self.dataset_cfg['img_width']*1.0/temp_image.shape[1]\n",
    "            ratio_h = self.dataset_cfg['img_height']*1.0/temp_image.shape[0]\n",
    "            temp_image = cv2.resize(temp_image, (self.dataset_cfg['img_width'],self.dataset_cfg['img_height']))\n",
    "            inputs.append( np.rollaxis(temp_image, axis=2, start=0) )\n",
    "\n",
    "            temp_lanes = []\n",
    "            temp_h = []\n",
    "\n",
    "            # annoatation = self.p.train_root_url+data[0:-4]+\"lines.txt\"\n",
    "            annotation = os.path.join(self.dataset_root, f\"{train_img[0:-4]}lines.txt\")\n",
    "            with open(annotation) as f:\n",
    "                annoatation_data = f.readlines()         \n",
    "\n",
    "            for j in annoatation_data:\n",
    "                x = []\n",
    "                y = []\n",
    "                temp_x = j.split()[0::2]\n",
    "                temp_y = j.split()[1::2]\n",
    "\n",
    "                for k in range(len(temp_x)):\n",
    "                    x_value = float(temp_x[k])\n",
    "                    y_value = int(float(temp_y[k]))\n",
    "                    if 0 < x_value < original_size_x and 0 < y_value < original_size_y:\n",
    "                        x.append( x_value )\n",
    "                        y.append( y_value )\n",
    "\n",
    "                l, h = self.make_dense_x(np.array(x), np.array(y))\n",
    "                temp_lanes.append( l*ratio_w )\n",
    "                temp_h.append( h*ratio_h )\n",
    "            target_lanes.append(np.array(temp_lanes))\n",
    "            target_h.append(np.array(temp_h))\n",
    "\n",
    "        #test set image\n",
    "        test_index = random.randrange(0, self.size_test-1)\n",
    "        # test_image = cv2.imread(self.p.test_root_url+self.test_data[test_index][1:-1])\n",
    "        print(f\"Test debug >>> {self.test_data[test_index][0:-1]}\")\n",
    "        train_image = cv2.imread(os.path.join(self.dataset_root, self.test_data[test_index][0:-1]))\n",
    "        train_image = cv2.resize(train_image, (self.dataset_cfg['img_width'],self.dataset_cfg['img_height']))\n",
    "        \n",
    "        return np.array(inputs), target_lanes, target_h, np.rollaxis(train_image, axis=2, start=0), data_list\n",
    "\n",
    "    def make_dense_x(self, l, h):\n",
    "        out_x = []\n",
    "        out_y = []\n",
    "\n",
    "        p_x = -1\n",
    "        p_y = -1\n",
    "        for x, y in zip(l, h):\n",
    "            if x > 0:\n",
    "                if p_x < 0:\n",
    "                    p_x = x\n",
    "                    p_y = y\n",
    "                else:\n",
    "                    out_x.append(x)\n",
    "                    out_y.append(y)\n",
    "                    for dense_x in range(min(int(p_x), int(x)), max(int(p_x), int(x)), 10):\n",
    "                        dense_y = p_y - abs(p_x - dense_x) * abs(p_y-y)/float(abs(p_x - x))\n",
    "                        if dense_x>=0 and dense_y>=0:\n",
    "                            out_x.append(dense_x)\n",
    "                            out_y.append( p_y - abs(p_x - dense_x) * abs(p_y-y)/float(abs(p_x - x)) )\n",
    "                    p_x = x\n",
    "                    p_y = y\n",
    "\n",
    "        return np.array(out_x), np.array(out_y)\n",
    "        #return l, h\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Generate random unique indices according to ratio\n",
    "    #################################################################################################################\n",
    "    def Random_indices(self, ratio):\n",
    "        size = int(self.actual_batchsize * ratio)\n",
    "        return np.random.choice(self.actual_batchsize, size, replace=False)\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Add Gaussian noise\n",
    "    #################################################################################################################\n",
    "    def Gaussian(self):\n",
    "        indices = self.Random_indices(self.dataset_cfg['noise_ratio'])\n",
    "        img = np.zeros((256,512,3), np.uint8)\n",
    "        m = (0,0,0) \n",
    "        s = (20,20,20)\n",
    "        \n",
    "        for i in indices:\n",
    "            test_image = deepcopy(self.inputs[i])\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "            cv2.randn(img,m,s)\n",
    "            test_image = test_image + img\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "            self.inputs[i] = test_image\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Change intensity\n",
    "    #################################################################################################################\n",
    "    def Change_intensity(self):\n",
    "        indices = self.Random_indices(self.dataset_cfg['intensity_ratio'])\n",
    "        for i in indices:\n",
    "            test_image = deepcopy(self.inputs[i])\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "\n",
    "            hsv = cv2.cvtColor(test_image, cv2.COLOR_BGR2HSV)\n",
    "            h, s, v = cv2.split(hsv)\n",
    "            value = int(random.uniform(-60.0, 60.0))\n",
    "            if value > 0:\n",
    "                lim = 255 - value\n",
    "                v[v > lim] = 255\n",
    "                v[v <= lim] += value\n",
    "            else:\n",
    "                lim = -1*value\n",
    "                v[v < lim] = 0\n",
    "                v[v >= lim] -= lim                \n",
    "            final_hsv = cv2.merge((h, s, v))\n",
    "            test_image = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "            self.inputs[i] = test_image\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Generate random shadow in random region\n",
    "    #################################################################################################################\n",
    "    def Shadow(self, min_alpha=0.5, max_alpha = 0.75):\n",
    "        indices = self.Random_indices(self.dataset_cfg['shadow_ratio'])\n",
    "        for i in indices:\n",
    "            test_image = deepcopy(self.inputs[i])\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "            test_image =  np.rollaxis(test_image, axis=2, start=0)\n",
    "\n",
    "            top_x, bottom_x = np.random.randint(0, 512, 2)\n",
    "            coin = 0\n",
    "            rows, cols, _ = test_image.shape\n",
    "            shadow_img = test_image.copy()\n",
    "            if coin == 0:\n",
    "                rand = np.random.randint(2)\n",
    "                vertices = np.array([[(50, 65), (45, 0), (145, 0), (150, 65)]], dtype=np.int32)\n",
    "                if rand == 0:\n",
    "                    vertices = np.array([[top_x, 0], [0, 0], [0, rows], [bottom_x, rows]], dtype=np.int32)\n",
    "                elif rand == 1:\n",
    "                    vertices = np.array([[top_x, 0], [cols, 0], [cols, rows], [bottom_x, rows]], dtype=np.int32)\n",
    "                mask = test_image.copy()\n",
    "                channel_count = test_image.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "                ignore_mask_color = (0,) * channel_count\n",
    "                cv2.fillPoly(mask, [vertices], ignore_mask_color)\n",
    "                rand_alpha = np.random.uniform(min_alpha, max_alpha)\n",
    "                cv2.addWeighted(mask, rand_alpha, test_image, 1 - rand_alpha, 0., shadow_img)\n",
    "                shadow_img =  np.rollaxis(shadow_img, axis=2, start=0)\n",
    "                self.inputs[i] = shadow_img\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Flip\n",
    "    #################################################################################################################\n",
    "    def Flip(self):\n",
    "        indices = self.Random_indices(self.dataset_cfg['flip_ratio'])\n",
    "        for i in indices:\n",
    "            temp_image = deepcopy(self.inputs[i])\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)\n",
    "\n",
    "            temp_image = cv2.flip(temp_image, 1)\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)\n",
    "            self.inputs[i] = temp_image\n",
    "\n",
    "            x = self.target_lanes[i]\n",
    "            for j in range(len(x)):\n",
    "                x[j][x[j]>0]  = self.dataset_cfg['img_width'] - x[j][x[j]>0]\n",
    "                x[j][x[j]<0] = -2\n",
    "                x[j][x[j]>=self.dataset_cfg['img_width']] = -2\n",
    "\n",
    "            self.target_lanes[i] = x\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Translation\n",
    "    #################################################################################################################\n",
    "    def Translation(self):\n",
    "        indices = self.Random_indices(self.dataset_cfg['translation_ratio'])\n",
    "        for i in indices:\n",
    "            temp_image = deepcopy(self.inputs[i])\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)       \n",
    "\n",
    "            tx = np.random.randint(-50, 50)\n",
    "            ty = np.random.randint(-30, 30)\n",
    "\n",
    "            temp_image = cv2.warpAffine(temp_image, np.float32([[1,0,tx],[0,1,ty]]), (self.dataset_cfg['img_width'], self.dataset_cfg['img_height']))\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)\n",
    "            self.inputs[i] = temp_image\n",
    "\n",
    "            x = self.target_lanes[i]\n",
    "            for j in range(len(x)):\n",
    "                x[j][x[j]>0]  = x[j][x[j]>0] + tx\n",
    "                x[j][x[j]<0] = -2\n",
    "                x[j][x[j]>=self.dataset_cfg['img_width']] = -2\n",
    "\n",
    "            y = self.target_h[i]\n",
    "            for j in range(len(y)):\n",
    "                y[j][y[j]>0]  = y[j][y[j]>0] + ty\n",
    "                x[j][y[j]<0] = -2\n",
    "                x[j][y[j]>=self.dataset_cfg['img_height']] = -2\n",
    "\n",
    "            self.target_lanes[i] = x\n",
    "            self.target_h[i] = y\n",
    "\n",
    "    #################################################################################################################\n",
    "    ## Rotate\n",
    "    #################################################################################################################\n",
    "    def Rotate(self):\n",
    "        indices = self.Random_indices(self.dataset_cfg['rotate_ratio'])\n",
    "        for i in indices:\n",
    "            temp_image = deepcopy(self.inputs[i])\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)  \n",
    "\n",
    "            angle = np.random.randint(-10, 10)\n",
    "\n",
    "            M = cv2.getRotationMatrix2D((self.dataset_cfg['img_width']//2, self.dataset_cfg['img_height']//2),angle,1)\n",
    "\n",
    "            temp_image = cv2.warpAffine(temp_image, M, (self.dataset_cfg['img_width'], self.dataset_cfg['img_height']))\n",
    "            temp_image =  np.rollaxis(temp_image, axis=2, start=0)\n",
    "            self.inputs[i] = temp_image\n",
    "\n",
    "            x = self.target_lanes[i]\n",
    "            y = self.target_h[i]\n",
    "\n",
    "            for j in range(len(x)):\n",
    "                index_mask = deepcopy(x[j]>0)\n",
    "                x[j][index_mask], y[j][index_mask] = Rotate_Points((self.dataset_cfg['img_width']//2, self.dataset_cfg['img_height']//2),(x[j][index_mask], y[j][index_mask]),(-angle * 2 * np.pi)/360)\n",
    "                x[j][x[j]<0] = -2\n",
    "                x[j][x[j]>=self.dataset_cfg['img_width']] = -2\n",
    "                x[j][y[j]<0] = -2\n",
    "                x[j][y[j]>=self.dataset_cfg['img_height']] = -2\n",
    "\n",
    "            self.target_lanes[i] = x\n",
    "            self.target_h[i] = y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fcba59-4594-458b-9f9f-854e43469773",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8df04269-8ba6-40aa-b8b0-faf2cfec6faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "Get dataset\n",
      "Get agent\n",
      "model parameters: \n",
      "4056849\n",
      "Setup GPU mode\n",
      "Testing loop\n",
      "[INFO]: Current Mode is >>> 0\n",
      "[INFO]: Mode-0\n",
      "Data >>> images/20240722_day_0_20240205102727-cam01-0000_output_000368.png\n",
      "mages/20240722_day_0_20240205102727-cam01-0000_output_000368.png\n",
      "Data >>> images/20240722_day_0_20240205102727-cam01-0000_output_000253.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thuratun/miniconda3/envs/PINet/lib/python3.7/site-packages/ipykernel_launcher.py:225: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/thuratun/miniconda3/envs/PINet/lib/python3.7/site-packages/ipykernel_launcher.py:226: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data >>> images/20240305_day_03_20240130150620-cam01-0000_output_000042.png\n",
      "Data >>> images/20240603_day_3_20240209113111-cam01-0000_3_20240209113111_multi_000202.png\n",
      "Data >>> images/20240419_day_2_20240111112939-cam01-0000_output_000250.png\n",
      "Data >>> images/20240419_day_4_20240209125600-cam01-0000_output_000989.png\n",
      "Data >>> images/20240419_day_4_20240209125600-cam01-0000_output_000563.png\n",
      "Data >>> images/20240220_day_20230626160617-cam01-Fr-Wide-0000_300_output_001014.png\n",
      "Data >>> images/20240722_night_13_20230626192922-cam01-0000_output_000349.png\n",
      "Data >>> images/20240305_day_03_20240130150620-cam01-0000_output_000120.png\n",
      "Data >>> images/20240722_night_13_20230626192922-cam01-0000_output_000549.png\n",
      "Data >>> images/20240214_night_Sig_2_20240118173029-cam01-0000_output_000266.png\n",
      "Test debug >>> images/20240419_day_2_20240111112939-cam01-0000_output_000074.png\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'flip_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37834/1868723432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m     \u001b[0mTesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_37834/1868723432.py\u001b[0m in \u001b[0;36mTesting\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;31m# check model with test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[INFO]: Mode-0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlane_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37834/1803123039.py\u001b[0m in \u001b[0;36mGenerate\u001b[0;34m(self, sampling_list)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactual_batchsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37834/1803123039.py\u001b[0m in \u001b[0;36mFlip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m#################################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandom_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flip_ratio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mtemp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'flip_ratio'"
     ]
    }
   ],
   "source": [
    "#############################################################################################################\n",
    "##\n",
    "##  Source code for testing\n",
    "##\n",
    "#############################################################################################################\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import torch\n",
    "import agent\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import time\n",
    "from parameters import Parameters\n",
    "import util\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from patsy import cr\n",
    "import csaps\n",
    "\n",
    "# from data_loader import DataGenerator\n",
    "\n",
    "p = Parameters()\n",
    "\n",
    "###############################################################\n",
    "##\n",
    "## Training\n",
    "## \n",
    "###############################################################\n",
    "def Testing():\n",
    "    print('Testing')\n",
    "    \n",
    "    #########################################################################\n",
    "    ## Get dataset\n",
    "    #########################################################################\n",
    "    print(\"Get dataset\")\n",
    "    loader = DataGenerator()\n",
    "\n",
    "    ##############################\n",
    "    ## Get agent and model\n",
    "    ##############################\n",
    "    print('Get agent')\n",
    "    if p.model_path == \"\":\n",
    "        lane_agent = agent.Agent()\n",
    "    else:\n",
    "        lane_agent = agent.Agent()\n",
    "        lane_agent.load_weights(168, \"tensor(0.8985)\")\n",
    "\t\n",
    "    ##############################\n",
    "    ## Check GPU\n",
    "    ##############################\n",
    "    print('Setup GPU mode')\n",
    "    if torch.cuda.is_available():\n",
    "        lane_agent.cuda()\n",
    "\n",
    "    ##############################\n",
    "    ## testing\n",
    "    ##############################\n",
    "    print('Testing loop')\n",
    "    lane_agent.evaluate_mode()\n",
    "    print(f\"[INFO]: Current Mode is >>> {p.mode}\")\n",
    "    if p.mode == 0 : # check model with test data \n",
    "        print(f\"[INFO]: Mode-0\")\n",
    "        for _, _, _, test_image in loader.Generate():\n",
    "            _, _, ti = test(lane_agent, np.array([test_image]))\n",
    "            cv2.imshow(\"test\", ti[0])\n",
    "            cv2.waitKey(0) \n",
    "\n",
    "    elif p.mode == 1: # check model with video\n",
    "        cap = cv2.VideoCapture(\"/home/kym/research/autonomous_car_vision/lane_detection/code/Tusimple/git_version/LocalDataset_Day.mp4\")\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "            torch.cuda.synchronize()\n",
    "            prevTime = time.time()\n",
    "            frame = cv2.resize(frame, (512,256))/255.0\n",
    "            frame = np.rollaxis(frame, axis=2, start=0)\n",
    "            _, _, ti = test(lane_agent, np.array([frame])) \n",
    "            curTime = time.time()\n",
    "            sec = curTime - prevTime\n",
    "            fps = 1/(sec)\n",
    "            s = \"FPS : \"+ str(fps)\n",
    "            ti[0] = cv2.resize(ti[0], (1280,800))\n",
    "            cv2.putText(ti[0], s, (0, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "            cv2.imshow('frame',ti[0])\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    elif p.mode == 2: # check model with a picture\n",
    "        #test_image = cv2.imread(p.test_root_url+\"clips/0530/1492720840345996040_0/20.jpg\")\n",
    "        test_image = cv2.imread(\"./aa.png\")\n",
    "        test_image = cv2.resize(test_image, (512,256))/255.0\n",
    "        test_image = np.rollaxis(test_image, axis=2, start=0)\n",
    "        _, _, ti = test(lane_agent, np.array([test_image]))\n",
    "        cv2.imshow(\"test\", ti[0])\n",
    "        cv2.waitKey(0)   \n",
    "\n",
    "    elif p.mode == 3: #evaluation\n",
    "        print(\"evaluate\")\n",
    "        evaluation(loader, lane_agent)\n",
    "\n",
    "############################################################################\n",
    "## evaluate on the test dataset\n",
    "############################################################################\n",
    "def evaluation(loader, lane_agent, thresh = p.threshold_point, index= -1, name = None):\n",
    "    progressbar = tqdm(range(loader.size_test//4))\n",
    "    for test_image, ratio_w, ratio_h, path, target_h, target_lanes in loader.Generate_Test():\n",
    "        x, y, _ = test(lane_agent, test_image, thresh, index= index)\n",
    "        print(f\"Ratio Width >>> {ratio_w}\")\n",
    "        print(f\"Ratio Height >>> {ratio_h}\")\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "        for i, j in zip(x, y):\n",
    "            temp_x, temp_y = util.convert_to_original_size(i, j, ratio_w, ratio_h)\n",
    "            print(f\"[Debug] temp_x >> {temp_x}\")\n",
    "            x_.append(temp_x)\n",
    "            y_.append(temp_y)\n",
    "        #x_, y_ = find_target(x_, y_, ratio_w, ratio_h)\n",
    "        x_, y_ = fitting(x_, y_, ratio_w, ratio_h)\n",
    "        print(f\"[Debug] x___ >> {x_}\")\n",
    "        #util.visualize_points_origin_size(x_[0], y_[0], test_image[0]*255, ratio_w, ratio_h)\n",
    "        #print(target_lanes)\n",
    "        #util.visualize_points_origin_size(target_lanes[0], target_h[0], test_image[0]*255, ratio_w, ratio_h)\n",
    "\n",
    "        result_data = write_result(x_, y_, path)\n",
    "        progressbar.update(1)\n",
    "    progressbar.close()\n",
    "\n",
    "############################################################################\n",
    "## linear interpolation for fixed y value on the test dataset\n",
    "############################################################################\n",
    "def find_target(x, y, ratio_w, ratio_h):\n",
    "    # find exact points on target_h\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "    x_size = p.x_size/ratio_w\n",
    "    y_size = p.y_size/ratio_h\n",
    "    for x_batch, y_batch in zip(x,y):\n",
    "        predict_x_batch = []\n",
    "        predict_y_batch = []\n",
    "        for i, j in zip(x_batch, y_batch):\n",
    "            min_y = min(j)\n",
    "            max_y = max(j)\n",
    "            temp_x = []\n",
    "            temp_y = []\n",
    "            for h in range(100, 590, 10):\n",
    "                temp_y.append(h)\n",
    "                if h < min_y:\n",
    "                    temp_x.append(-2)\n",
    "                elif min_y <= h and h <= max_y:\n",
    "                    for k in range(len(j)-1):\n",
    "                        if j[k] >= h and h >= j[k+1]:\n",
    "                            #linear regression\n",
    "                            if i[k] < i[k+1]:\n",
    "                                temp_x.append(int(i[k+1] - float(abs(j[k+1] - h))*abs(i[k+1]-i[k])/abs(j[k+1]+0.0001 - j[k])))\n",
    "                            else:\n",
    "                                temp_x.append(int(i[k+1] + float(abs(j[k+1] - h))*abs(i[k+1]-i[k])/abs(j[k+1]+0.0001 - j[k])))\n",
    "                            break\n",
    "                else:\n",
    "                    temp_x.append(-2)\n",
    "            predict_x_batch.append(temp_x)\n",
    "            predict_y_batch.append(temp_y)\n",
    "        out_x.append(predict_x_batch)\n",
    "        out_y.append(predict_y_batch)            \n",
    "    \n",
    "    return out_x, out_y\n",
    "\n",
    "def fitting(x, y, ratio_w, ratio_h):\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "    x_size = p.x_size/ratio_w\n",
    "    y_size = p.y_size/ratio_h\n",
    "\n",
    "    for x_batch, y_batch in zip(x,y):\n",
    "        predict_x_batch = []\n",
    "        predict_y_batch = []\n",
    "        for i, j in zip(x_batch, y_batch):\n",
    "            min_y = min(j)\n",
    "            max_y = max(j)\n",
    "            temp_x = []\n",
    "            temp_y = []\n",
    "\n",
    "            jj = []\n",
    "            pre = -100\n",
    "            for temp in j[::-1]:\n",
    "                if temp > pre:\n",
    "                    jj.append(temp)\n",
    "                    pre = temp\n",
    "                else:\n",
    "                    jj.append(pre+0.00001)\n",
    "                    pre = pre+0.00001\n",
    "            sp = csaps.CubicSmoothingSpline(jj, i[::-1], smooth=0.0001)\n",
    "\n",
    "            last = 0\n",
    "            last_second = 0\n",
    "            last_y = 0\n",
    "            last_second_y = 0\n",
    "            for pts in range(62, -1, -1):\n",
    "                h = 2160 - pts*5 - 1\n",
    "                temp_y.append(h)\n",
    "                if h < min_y:\n",
    "                    temp_x.append(-2)\n",
    "                elif min_y <= h and h <= max_y:\n",
    "                    temp_x.append( sp([h])[0] )\n",
    "                    last = temp_x[-1]\n",
    "                    last_y = temp_y[-1]\n",
    "                    if len(temp_x)<2:\n",
    "                        last_second = temp_x[-1]\n",
    "                        last_second_y = temp_y[-1]\n",
    "                    else:\n",
    "                        last_second = temp_x[-2]\n",
    "                        last_second_y = temp_y[-2]\n",
    "                else:\n",
    "                    if last < last_second:\n",
    "                        l = int(last_second - float(-last_second_y + h)*abs(last_second-last)/abs(last_second_y+0.0001 - last_y))\n",
    "                        if l > x_size or l < 0 :\n",
    "                            temp_x.append(-2)\n",
    "                        else:\n",
    "                            temp_x.append(l)\n",
    "                    else:\n",
    "                        l = int(last_second + float(-last_second_y + h)*abs(last_second-last)/abs(last_second_y+0.0001 - last_y))\n",
    "                        if l > x_size or l < 0 :\n",
    "                            temp_x.append(-2)\n",
    "                        else:\n",
    "                            temp_x.append(l)\n",
    "            predict_x_batch.append(temp_x[::-1])\n",
    "            predict_y_batch.append(temp_y[::-1])\n",
    "        out_x.append(predict_x_batch)\n",
    "        out_y.append(predict_y_batch) \n",
    "\n",
    "\n",
    "    return out_x, out_y\n",
    "\n",
    "############################################################################\n",
    "## write result\n",
    "############################################################################\n",
    "def write_result(x, y, path):\n",
    "    \n",
    "    batch_size = len(path)\n",
    "    save_path = \"test_out\"\n",
    "    for i in range(batch_size):\n",
    "        # print(f\"[Debug]: paht >>> {path}\")\n",
    "        path_detail = path[i].split(\"/\")\n",
    "        # print(f\"[Debug]: path_detal >>> {path_detail}\")\n",
    "        first_folder = path_detail[0]\n",
    "        print(f\"[Debug]: First Folder >>> {first_folder}\")\n",
    "        second_folder = path_detail[1]\n",
    "        # print(f\"[Debug]: Second Folder >>> {second_folder}\")\n",
    "        file_name = path_detail[1].split(\".\")[0]+\".lines.txt\"\n",
    "        print(f\"[Debug]: Filename >>> {file_name}\")\n",
    "        if not os.path.exists(save_path+\"/\"+first_folder):\n",
    "            os.makedirs(save_path+\"/\"+first_folder)\n",
    "        # if not os.path.exists(save_path+\"/\"+first_folder):\n",
    "        #     os.makedirs(save_path+\"/\"+first_folder)      \n",
    "        with open(save_path+\"/\"+file_name, \"w\") as f:  \n",
    "            for x_values, y_values in zip(x[i], y[i]):\n",
    "                # print(f\"[Debug]: X >> {x_values}\")\n",
    "                # print(f\"[Debug]: Y >> {y_values}\")\n",
    "                count = 0\n",
    "                if np.sum(np.array(x_values)>=0) > 1 : ######################################################\n",
    "                    print(f\"[INFO]: Pass \")\n",
    "                    for x_value, y_value in zip(x_values, y_values):\n",
    "                        if x_value >= 0:\n",
    "                            f.write(str(x_value) + \" \" + str(y_value) + \" \")\n",
    "                            count += 1\n",
    "                    if count>1:\n",
    "                        f.write(\"\\n\")\n",
    "\n",
    "\n",
    "############################################################################\n",
    "## save result by json form\n",
    "############################################################################\n",
    "def save_result(result_data, fname):\n",
    "    with open(fname, 'w') as make_file:\n",
    "        for i in result_data:\n",
    "            json.dump(i, make_file, separators=(',', ': '))\n",
    "            make_file.write(\"\\n\")\n",
    "\n",
    "############################################################################\n",
    "## test on the input test image\n",
    "############################################################################\n",
    "def test(lane_agent, test_images, thresh = p.threshold_point, index= -1):\n",
    "\n",
    "    result = lane_agent.predict_lanes_test(test_images)\n",
    "    torch.cuda.synchronize()\n",
    "    confidences, offsets, instances = result[index]\n",
    "    \n",
    "    num_batch = len(test_images)\n",
    "\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "    out_images = []\n",
    "    \n",
    "    for i in range(num_batch):\n",
    "        # test on test data set\n",
    "        image = deepcopy(test_images[i])\n",
    "        image =  np.rollaxis(image, axis=2, start=0)\n",
    "        image =  np.rollaxis(image, axis=2, start=0)*255.0\n",
    "        image = image.astype(np.uint8).copy()\n",
    "\n",
    "        confidence = confidences[i].view(p.grid_y, p.grid_x).cpu().data.numpy()\n",
    "\n",
    "        offset = offsets[i].cpu().data.numpy()\n",
    "        offset = np.rollaxis(offset, axis=2, start=0)\n",
    "        offset = np.rollaxis(offset, axis=2, start=0)\n",
    "        \n",
    "        instance = instances[i].cpu().data.numpy()\n",
    "        instance = np.rollaxis(instance, axis=2, start=0)\n",
    "        instance = np.rollaxis(instance, axis=2, start=0)\n",
    "\n",
    "        # generate point and cluster\n",
    "        raw_x, raw_y = generate_result(confidence, offset, instance, thresh)\n",
    "\n",
    "        # eliminate fewer points\n",
    "        in_x, in_y = eliminate_fewer_points(raw_x, raw_y)\n",
    "                \n",
    "        # sort points along y \n",
    "        in_x, in_y = util.sort_along_y(in_x, in_y)  \n",
    "\n",
    "        result_image = util.draw_points(in_x, in_y, deepcopy(image))\n",
    "\n",
    "        out_x.append(in_x)\n",
    "        out_y.append(in_y)\n",
    "        out_images.append(result_image)\n",
    "\n",
    "    return out_x, out_y,  out_images\n",
    "\n",
    "############################################################################\n",
    "## eliminate result that has fewer points than threshold\n",
    "############################################################################\n",
    "def eliminate_fewer_points(x, y):\n",
    "    # eliminate fewer points\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "    for i, j in zip(x, y):\n",
    "        if len(i)>5:\n",
    "            out_x.append(i)\n",
    "            out_y.append(j)     \n",
    "    return out_x, out_y   \n",
    "\n",
    "############################################################################\n",
    "## generate raw output\n",
    "############################################################################\n",
    "def generate_result(confidance, offsets,instance, thresh):\n",
    "\n",
    "    mask = confidance > thresh\n",
    "\n",
    "    grid = p.grid_location[mask]\n",
    "    offset = offsets[mask]\n",
    "    feature = instance[mask]\n",
    "\n",
    "    lane_feature = []\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(grid)):\n",
    "        if (np.sum(feature[i]**2))>=0:\n",
    "            point_x = int((offset[i][0]+grid[i][0])*p.resize_ratio)\n",
    "            point_y = int((offset[i][1]+grid[i][1])*p.resize_ratio)\n",
    "            if point_x > p.x_size or point_x < 0 or point_y > p.y_size or point_y < 0:\n",
    "                continue\n",
    "            if len(lane_feature) == 0:\n",
    "                lane_feature.append(feature[i])\n",
    "                x.append([point_x])\n",
    "                y.append([point_y])\n",
    "            else:\n",
    "                flag = 0\n",
    "                index = 0\n",
    "                min_feature_index = -1\n",
    "                min_feature_dis = 10000\n",
    "                for feature_idx, j in enumerate(lane_feature):\n",
    "                    dis = np.linalg.norm((feature[i] - j)**2)\n",
    "                    if min_feature_dis > dis:\n",
    "                        min_feature_dis = dis\n",
    "                        min_feature_index = feature_idx\n",
    "                if min_feature_dis <= p.threshold_instance:\n",
    "                    lane_feature[min_feature_index] = (lane_feature[min_feature_index]*len(x[min_feature_index]) + feature[i])/(len(x[min_feature_index])+1)\n",
    "                    x[min_feature_index].append(point_x)\n",
    "                    y[min_feature_index].append(point_y)\n",
    "                elif len(lane_feature) < 12:\n",
    "                    lane_feature.append(feature[i])\n",
    "                    x.append([point_x])\n",
    "                    y.append([point_y])\n",
    "                \n",
    "    return x, y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Testing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fe4d0b98-0e1b-47c4-ab14-3853de11da33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"dataset/small-client/images/20240305_night_6_20240207174637-cam01-0000_output_000510.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "846685c6-e0e7-4cd9-96b2-2bad743eda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"dataset/small-client/images/20240305_night_6_20240207174637-cam01-0000_output_000510.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2ccb227d-9f4d-455d-857e-7793acb51c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 3840, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dcb14b37-2d06-4d1d-ad8b-1de7d8c0667d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (962689933.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5599/962689933.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    j = 666.3 2160.0 688.9953333333333 2142.539333333333 711.6906666666666 2125.078666666667 734.386 2107.618 757.0813333333333 2090.1573333333336 779.7766666666666 2072.6966666666667 802.472 2055.236 825.1673333333333 2037.7753333333335 847.8626666666667 2020.3146666666667 870.558 2002.854 893.2533333333333 1985.3933333333334 915.9486666666667 1967.9326666666668 938.644 1950.4720000000002 961.3393333333333 1933.0113333333334 984.0346666666667 1915.5506666666668 1006.73 1898.0900000000001 1029.4253333333334 1880.6293333333335 1052.1206666666667 1863.1686666666667 1074.816 1845.708 1097.5113333333334 1828.2473333333332 1120.2066666666667 1810.7866666666666 1142.902 1793.326 1165.5973333333334 1775.8653333333334 1188.2926666666667 1758.4046666666666 1210.988 1740.944 1233.6833333333334 1723.4833333333333 1256.3786666666667 1706.0226666666667 1279.074 1688.5620000000001 1301.7693333333334 1671.1013333333333 1324.4646666666667 1653.6406666666667 1347.16 1636.18 1367.3433333333335 1620.7516666666668 1387.5266666666666 1605.3233333333335 1407.71 1589.895 1427.8933333333334 1574.4666666666667 1448.0766666666666 1559.0383333333334 1468.26 1543.6100000000001 1488.4433333333334 1528.1816666666668 1508.6266666666668 1512.7533333333333 1528.81 1497.325 1548.9933333333333 1481.8966666666668 1569.1766666666667 1466.4683333333332 1589.3600000000001 1451.04 1609.5433333333335 1435.6116666666667 1629.7266666666667 1420.1833333333334 1649.91 1404.755 1670.0933333333335 1389.3266666666666 1690.2766666666666 1373.8983333333333 1710.46 1358.47 1732.412 1341.618 1754.364 1324.766 1776.316 1307.914 1798.268 1291.0620000000001 1820.22 1274.21 1840.74 1259.2325 1861.26 1244.255 1881.78 1229.2775 1902.3 1214.3\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "j = 666.3 2160.0 688.9953333333333 2142.539333333333 711.6906666666666 2125.078666666667 734.386 2107.618 757.0813333333333 2090.1573333333336 779.7766666666666 2072.6966666666667 802.472 2055.236 825.1673333333333 2037.7753333333335 847.8626666666667 2020.3146666666667 870.558 2002.854 893.2533333333333 1985.3933333333334 915.9486666666667 1967.9326666666668 938.644 1950.4720000000002 961.3393333333333 1933.0113333333334 984.0346666666667 1915.5506666666668 1006.73 1898.0900000000001 1029.4253333333334 1880.6293333333335 1052.1206666666667 1863.1686666666667 1074.816 1845.708 1097.5113333333334 1828.2473333333332 1120.2066666666667 1810.7866666666666 1142.902 1793.326 1165.5973333333334 1775.8653333333334 1188.2926666666667 1758.4046666666666 1210.988 1740.944 1233.6833333333334 1723.4833333333333 1256.3786666666667 1706.0226666666667 1279.074 1688.5620000000001 1301.7693333333334 1671.1013333333333 1324.4646666666667 1653.6406666666667 1347.16 1636.18 1367.3433333333335 1620.7516666666668 1387.5266666666666 1605.3233333333335 1407.71 1589.895 1427.8933333333334 1574.4666666666667 1448.0766666666666 1559.0383333333334 1468.26 1543.6100000000001 1488.4433333333334 1528.1816666666668 1508.6266666666668 1512.7533333333333 1528.81 1497.325 1548.9933333333333 1481.8966666666668 1569.1766666666667 1466.4683333333332 1589.3600000000001 1451.04 1609.5433333333335 1435.6116666666667 1629.7266666666667 1420.1833333333334 1649.91 1404.755 1670.0933333333335 1389.3266666666666 1690.2766666666666 1373.8983333333333 1710.46 1358.47 1732.412 1341.618 1754.364 1324.766 1776.316 1307.914 1798.268 1291.0620000000001 1820.22 1274.21 1840.74 1259.2325 1861.26 1244.255 1881.78 1229.2775 1902.3 1214.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5d01c-2089-470f-94ca-6ca66e97a7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
